{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nilearn\n",
    "import nibabel as nb\n",
    "from nilearn.decoding import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"data/\"\n",
    "\n",
    "stim_on_files = []\n",
    "stim_off_files = []\n",
    "for file in sorted(os.listdir(parent_dir)):\n",
    "    if \"task-sp\" in file and \"brain_mask\" not in file:\n",
    "        stim_on_files.append(os.path.join(parent_dir, file))\n",
    "    elif \"task-mv\" in file and \"brain_mask\" not in file:\n",
    "        stim_off_files.append(os.path.join(parent_dir, file))\n",
    "\n",
    "stim_on_labels = [0]*len(stim_on_files)\n",
    "stim_off_labels = [0]*len(stim_off_files)\n",
    "\n",
    "X = stim_off_files\n",
    "for file in stim_on_files:\n",
    "    X.append(file)\n",
    "y = stim_off_labels\n",
    "for label in stim_on_labels:\n",
    "    y.append(label)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files are fine\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "for file in stim_on_files:\n",
    "    loaded_data = nb.load(file)\n",
    "    if loaded_data.shape != (57, 68, 65, 244):\n",
    "        print(file, loaded_data.shape)\n",
    "        flag = 1\n",
    "if flag == 1:\n",
    "    print(\"files are not fine\")\n",
    "else:\n",
    "    print(\"files are fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Field of view of image #1 is different from reference FOV.\nReference affine:\narray([[   3.43799996,    0.        ,    0.        ,  -96.5       ],\n       [   0.        ,    3.43700004,    0.        , -132.5       ],\n       [   0.        ,    0.        ,    3.        ,  -78.5       ],\n       [   0.        ,    0.        ,    0.        ,    1.        ]])\nImage affine:\narray([[   3.43799996,    0.        ,    0.        ,  -96.5       ],\n       [   0.        ,    3.43799996,    0.        , -132.5       ],\n       [   0.        ,    0.        ,    3.        ,  -78.5       ],\n       [   0.        ,    0.        ,    0.        ,    1.        ]])\nReference shape:\n(57, 68, 65)\nImage shape:\n(57, 68, 65, 244)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m'\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m coef_img \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mcoef_img_\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/decoding/decoder.py:456\u001b[0m, in \u001b[0;36m_BaseDecoder.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m _check_estimator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_ \u001b[38;5;241m=\u001b[39m _check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m--> 456\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/decoding/decoder.py:657\u001b[0m, in \u001b[0;36m_BaseDecoder._apply_mask\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# Nifti masking\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker_ \u001b[38;5;241m=\u001b[39m _check_embedded_nifti_masker(\u001b[38;5;28mself\u001b[39m, multi_subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 657\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasker_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_img_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker_\u001b[38;5;241m.\u001b[39mmask_img_\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/maskers/base_masker.py:285\u001b[0m, in \u001b[0;36mBaseMasker.fit_transform\u001b[0;34m(self, X, y, confounds, sample_mask, **fit_params)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X, confounds\u001b[38;5;241m=\u001b[39mconfounds,\n\u001b[1;32m    287\u001b[0m                                     sample_mask\u001b[38;5;241m=\u001b[39msample_mask)\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X,\n\u001b[1;32m    290\u001b[0m                                                 confounds\u001b[38;5;241m=\u001b[39mconfounds,\n\u001b[1;32m    291\u001b[0m                                                 sample_mask\u001b[38;5;241m=\u001b[39msample_mask\n\u001b[1;32m    292\u001b[0m                                                 )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/maskers/nifti_masker.py:452\u001b[0m, in \u001b[0;36mNiftiMasker.fit\u001b[0;34m(self, imgs, y)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.fit] Computing the mask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_img_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmask_args\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_img_ \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mcheck_niimg_3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_img)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/masking.py:427\u001b[0m, in \u001b[0;36mcompute_background_mask\u001b[0;34m(data_imgs, border_size, connected, opening, target_affine, target_shape, memory, verbose)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground mask computation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 427\u001b[0m data_imgs \u001b[38;5;241m=\u001b[39m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_niimg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_imgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Delayed import to avoid circular imports\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compute_mean\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py:283\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_iterator:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _iter_check_niimg(niimg, ensure_ndim\u001b[38;5;241m=\u001b[39mensure_ndim,\n\u001b[1;32m    282\u001b[0m                                  dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcat_niimgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mniimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[39;00m\n\u001b[1;32m    286\u001b[0m niimg \u001b[38;5;241m=\u001b[39m load_niimg(niimg, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py:487\u001b[0m, in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    484\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(target_shape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28msum\u001b[39m(lengths), ),\n\u001b[1;32m    485\u001b[0m                   order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    486\u001b[0m cur_4d_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (size, niimg) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(lengths, _iter_check_niimg(\n\u001b[1;32m    488\u001b[0m         iterator, atleast_4d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, target_fov\u001b[38;5;241m=\u001b[39mtarget_fov,\n\u001b[1;32m    489\u001b[0m         memory\u001b[38;5;241m=\u001b[39mmemory, memory_level\u001b[38;5;241m=\u001b[39mmemory_level))):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(niimg, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py:160\u001b[0m, in \u001b[0;36m_iter_check_niimg\u001b[0;34m(niimgs, ensure_ndim, atleast_4d, target_fov, dtype, memory, memory_level, verbose)\u001b[0m\n\u001b[1;32m    154\u001b[0m             niimg \u001b[38;5;241m=\u001b[39m cache(image\u001b[38;5;241m.\u001b[39mresample_img, memory,\n\u001b[1;32m    155\u001b[0m                           func_memory_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    156\u001b[0m                           memory_level\u001b[38;5;241m=\u001b[39mmemory_level)(\n\u001b[1;32m    157\u001b[0m                     niimg, target_affine\u001b[38;5;241m=\u001b[39mref_fov[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    158\u001b[0m                     target_shape\u001b[38;5;241m=\u001b[39mref_fov[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField of view of image #\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is different from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference FOV.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference affine:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImage affine:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference shape:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImage shape:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m                 \u001b[38;5;241m%\u001b[39m (i, ref_fov[\u001b[38;5;241m0\u001b[39m], niimg\u001b[38;5;241m.\u001b[39maffine, ref_fov[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    166\u001b[0m                    niimg\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m niimg\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DimensionError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Keep track of the additional dimension in the error\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Field of view of image #1 is different from reference FOV.\nReference affine:\narray([[   3.43799996,    0.        ,    0.        ,  -96.5       ],\n       [   0.        ,    3.43700004,    0.        , -132.5       ],\n       [   0.        ,    0.        ,    3.        ,  -78.5       ],\n       [   0.        ,    0.        ,    0.        ,    1.        ]])\nImage affine:\narray([[   3.43799996,    0.        ,    0.        ,  -96.5       ],\n       [   0.        ,    3.43799996,    0.        , -132.5       ],\n       [   0.        ,    0.        ,    3.        ,  -78.5       ],\n       [   0.        ,    0.        ,    0.        ,    1.        ]])\nReference shape:\n(57, 68, 65)\nImage shape:\n(57, 68, 65, 244)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(estimator='svc', scoring='accuracy')\n",
    "decoder.fit(X_train, y_train)\n",
    "coef_img = decoder.coef_img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
